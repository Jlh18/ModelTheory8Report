For most definitions and proofs in this section we reference
David Marker's book on Model Theory \cite{marker}.
We introduce the formalisations of the content in \texttt{lean} alongside the theory,
walking through the basics of definitions made in the \texttt{flypitch} project \cite{flypitch}.
My work is based on a slightly updated (3.33.0) version of the flypitch project,
combined with some of the model theory material put in \texttt{mathlib} (which was edited for compatibility).

\subsection{Languages}
\begin{dfn}[Language]
  A language (also known as a \textit{signature}) $\LL = ( \func , \rel )$ consists of

  \begin{itemize}
    \item A sort symbol $A$, which we will have in the background for intuition.
    \item For each natural number $n$ we have $\func n$ -
          the set of \textit{function symbols} of \textit{arity} $n$ for the language.
          For some $f \in \func n$ we might write
          $f : A^{n} \to A$ to denote $f$ with its arity.
    \item For each natural number $n$ we have $\rel n$ -
          the set of \textit{relation symbols} of \textit{arity} $n$ for the language.
          For some $r \in \rel n$ we might write
          $r \hookr A^{n}$ to denote $r$ with its arity.
  \end{itemize}

  The \texttt{flypitch} project implements the above definition as

  \begin{lstlisting}
    structure Language : Type (u+1) :=
      (functions : ℕ → Type u)
      (relations : ℕ → Type u)\end{lstlisting}

  This says that \texttt{Language} is a mathematical structure
  (like a group structure, or ring structure)
  that consists of two pieces of data,
  a map called \texttt{functions} and another called \texttt{relations}.
  Both take a natural number and spit out a \textit{type}
  (which in \texttt{lean} might as well mean \textit{set})
  that consists respectively of all the function symbols and relation symbols of arity $n$.

  In more detail: in type theory when we write \texttt{a:A} we mean \texttt{a} is something
  of \textit{type} \texttt{A}.
  We can draw an analogy with the set theoretic notion $a \in A$,
  but types in \texttt{lean} have slightly different
  personalities, which we will gradually introduce.
  Hence in the above definitions \texttt{functions n} and \texttt{relations n}
  are things of type \texttt{Type u}.
  \texttt{Type u} is a collection of all types at level \texttt{u},
  so things of type \texttt{Type u} are types.
  ``Types are type \texttt{Type u}.''

  For convenience we single out $0$-ary (arity $0$) functions and
  call them \textit{constant} symbols, usually denoting them by $c : A$.
  We think of these as `elements' of the sort $A$ and write $c : A$.
  This is defined in \texttt{lean} by

  \begin{lstlisting}
    def constants (L : Language) : Type u := functions 0\end{lstlisting}

  This says that \texttt{constants} takes in a language $L$ and returns a type.
  Following the \texttt{:=} we have the definition of \texttt{constants L},
  which is the type \texttt{functions 0}.
\end{dfn}

\begin{eg}
  The \linkto{dfn_rings}{language of rings}
  will be used to define the theory of rings,
  the theory of integral domains, the theory of fields, and so on.
  In the appendix we give examples:
  \begin{itemize}
    \item The \linkto{dfn_bin_rel}{language with just a single binary relation} %? missing
          can be used to define the theory of partial orders
          with the interpretation of the relation as $<$,
          to define the theory of equivalence relations with the
          interpretation of the relation as $\sim$,
          and to define the theory $\ZFC$ with the relation interpreted as $\in$.
    \item The \linkto{dfn_cat}{language of categories} %? missing
          can be used to define the theory of categories.
    \item The \linkto{dfn_graph}{language of simple graphs}
          can be used to define the theory of simple graphs
  \end{itemize}
  We will only be concerned with the language of rings and will
  focus our examples around this.
\end{eg}

\begin{dfn}[Language of rings]
    \link{dfn_rings}
    Let the following be the language of rings:
    \begin{itemize}
        \item The function symbols are the constant symbols $0, 1 : A$,
        the symbols for addition and multiplication $+ , \times : A^2 \to A$
        and taking for inverse $- : A \to A$.
        \item There are no relation symbols.
    \end{itemize}

    We can break this definition up into steps in \texttt{lean}.
    We first collect the constant, unary and binary symbols:

    \begin{lstlisting}
      /-- The constant symbols in RingLanguage -/
      inductive ring_consts : Type u
      | zero : ring_consts
      | one : ring_consts

      /-- The unary function symbols in RingLanguage-/
      inductive ring_unaries : Type u
      | neg : ring_unaries

      /-- The binary function symbols in RingLanguage-/
      inductive ring_binaries : Type u
      | add : ring_binaries
      | mul : ring_binaries\end{lstlisting}

    These are \textit{inductively defined types} -
    types that are `freely' generated by their constructors,
    listed below after each bar `\texttt{|}'.
    In these above cases they are particularly simple -
    the only constructors are terms in the type.
    In the appendix we give more examples of inductive types %? missing
    \begin{itemize}
      \item The \link{dfn_nat}{natural numbers} are defined as inductive types
      \item \link{dfn_list}{Lists} are defined as inductive types
      \item The \link{dfn_int}{integers} can be defined as inductive types
    \end{itemize}

    We now collect all the above into a single definition \texttt{ring funcs}
    that takes each natural \texttt{n} to the type of \texttt{n}-ary
    function symbols in the language of rings.

    \begin{lstlisting}
      /-- All function symbols in RingLanguage-/
      def ring_funcs : ℕ → Type u
      | 0 := ring_consts
      | 1 := ring_unaries
      | 2 := ring_binaries
      | (n + 3) := pempty\end{lstlisting}

    The type \texttt{pempty} is the empty type and is meant to have no terms in it,
    since we wish to have no function symbols beyond arity $2$.
    Finally we make the language of rings

    \begin{lstlisting}
      /-- The language of rings -/
      def ring_language : Language :=
      (Language.mk) (ring_funcs) (λ n, pempty)\end{lstlisting}

\end{dfn}

We use languages to express logical assertions about our structures, such as
``any degree two polynomial over my ring has a root''.
In order to do so we must introduce terms (polynomials in our case),
formulas (the assertion itself), structures and models (the ring),
and the relation between structures and formulas
(that the ring satisfies this assertion).

We want to express ``all the combinations of symbols we can make in a language''.
We can think of multivariable polynomials over the integers as such:
the only things we can write down using symbols $0,1,-,+,*$ and variables
are elements of $\Z{[x_{k}]}_{k \in \N}$.
We formalize this as terms.

\subsection{Terms and formulas}

\begin{dfn}[Terms]
  Let $\LL = (\func, \rel)$ be a language.
  To make a \textit{preterm} in $\LL$ with up to $n$ variables
  we can do one of three things:
  \begin{itemize}
    \item[$\vert$] For each natural number $k < n$ we create a symbol
          $x_{k}$, which we call a \textit{variable} in $A$.
          Any $x_{k}$ is a preterm (that is missing nothing).
    \item[$\vert$] If $f : A^{l} \to A$ is a function symbol then
          $f$ is a preterm that is missing $l$ inputs.
          \[ f( ? , \cdots , ? )\]
    \item[$\vert$] If $t$ is a preterm that is missing
          $l + 1$ inputs and $s$ is a preterm that is missing
          no inputs then we can \textit{apply} $t$ to $s$, obtaining
          a preterm that is missing $l$ inputs.
          \[ t(s , ? , \cdots, ? )\]
  \end{itemize}

  We only really want \textit{terms} with up to $n$ variables,
  which are defined as preterms that are missing nothing.

  \begin{lstlisting}
    inductive bounded_preterm (n : ℕ) : ℕ → Type u
    | x_ : ∀ (k : fin n), bounded_preterm 0
    | bd_func : ∀ {l : ℕ} (f : L.functions l), bounded_preterm l
    | bd_app : ∀ {l : ℕ} (t : bounded_preterm (l + 1)) (s : bounded_preterm 0), bounded_preterm l

  def bounded_term (n : ℕ) := bounded_preterm L n 0\end{lstlisting}

  To explain notation
  \begin{itemize}
    \item The second constructor says ``for all natural numbers $l$ and function symbols $f$,
          \texttt{bd\_func f} is something in \texttt{bounded\_preterm l}''.
          This makes sense since \texttt{bounded\_preterm l} is a type by the first line of code.
    \item The curley brackets just say
          ``you can leave out this input and \texttt{lean} will know what it is''.
  \end{itemize}

  To give an example of this in action we can write $x_{1} * 0$.
  We first write the individual parts, which are
  \texttt{x\_ 1}, \texttt{bd\_func mul} and
  \texttt{bd\_func zero}.
  Then we apply them to each other
  \begin{lstlisting}
    bd_app (bd_app (mul) (x_ 1)) zero \end{lstlisting}
  Naturally, we will introduce nice notation in \texttt{lean} to replace all of this.
\end{dfn}

\begin{rmk}
  There are many terminology clashes between model theory and type theory,
  since they are closely related.
  The word ``term'' in type theory refers to anything on the left of a \texttt{:} sign,
  or anything in a type.
  Terms in inductively defined types are (as mentioned before)
  freely generated symbols using the contructors.
  Analogously terms in a language are freely generated symbols using
  the symbols from the language.
\end{rmk}

One can imagine writing down any degree two polynomial over the integers
as a term in the language of rings.
In fact, we could even make degree two polynomials over any ring (if we had one):
\[ x_{0} x_{3}^{2} + x_{1} x_{3} + x_{2} \]
Here our variable is $x_{3}$, and we imaging that the other variables represent
elements of our ring.

To express ``any degree (up to) two polynomial over our ring has a root'',
we might write
\[ \forall x_{2} x_{1} x_{0} : A, \exists x_{3} : A, x_{0} x_{3}^{2} + x_{1} x_{3} + x_{2} = 0 \]
Formulas allow us to do this.

\begin{dfn}[Formulas]
  Let $\LL$ be a language.
  A (classical first order) $\LL$-\textit{preformula} in $\LL$
  with (up to) $n$ \textit{free} variables can be built in the following ways:
  \begin{itemize}
    \item[$\vert$] $\bot$ is an atomic preformula with $n$ free variables
          (and missing nothing).
    \item[$\vert$]
          Given terms $t, s$ with $n$ variables,
          $t = s$ is a formula with $n$ free variables (missing nothing).
    \item[$\vert$] Any relation symbol $r \hookr A^{l}$ is a preformula
          with $n$ free variables and missing $l$ inputs.
          \[ r (?, \cdots, ?)\]
    \item[$\vert$] If $\phi$ is a preformula with $n$ free variables that is missing
          $l + 1$ inputs and $t$ is a term with $n$ variables
          then we can \textit{apply} $\phi$ to $t$, obtaining
          a preformula that is missing $l$ inputs.
          \[ \phi(t , ? , \cdots, ? )\]
    \item[$\vert$] If $\phi$ and $\psi$ are preformulas with $n$ free variables
          and \textit{nothing missing} then so is $\phi \implies \psi$.
    \item[$\vert$] If $\phi$ is a preformula with $n + 1$ free variables
          and \textit{nothing missing} then $\forall x_{0}, \phi$ is a preformula
          with $n$ free variables and nothing missing.
  \end{itemize}

  We take formulas to be preformulas with nothing missing.
  Note that we take the de Brujn index convension here.
  If $\phi$ were the formula $x_{0} + x_{1} = x_{2}$ then $\forall \phi$ would be
  the formula $\forall x_{0} : A, x_{0} + x_{1} = x_{2}$,
  which is really $\forall x : A, x + x_{0} = x_{1}$,
  so that all the remaining free variables are shifted down.

  We write this in \texttt{lean},
  and also define sentences as preformulas with $0$ variables and nothing missing.
  Sentences are what we usually come up with when we make assertions.
  For example $x = 0$ is not an assersion about rings,
  but $\forall x : A, x = 0$ is.

  \begin{lstlisting}
    inductive bounded_preformula : ℕ → ℕ → Type u
    | bd_falsum {n : ℕ} : bounded_preformula n 0
    | bd_equal {n : ℕ} (t₁ t₂ : bounded_term L n) : bounded_preformula n 0
    | bd_rel {n l : ℕ} (R : L.relations l) : bounded_preformula n l
    | bd_apprel {n l : ℕ} (f : bounded_preformula n (l + 1)) (t : bounded_term L n) : bounded_preformula n l
    | bd_imp {n : ℕ} (f₁ f₂ : bounded_preformula n 0) : bounded_preformula n 0
    | bd_all {n : ℕ} (f : bounded_preformula (n+1) 0) : bounded_preformula n 0

    def bounded_formula (n : ℕ) := bounded_preformula L n 0
    def sentence := bounded_preformula L 0 0\end{lstlisting}

  Since we are working with classical logic we
  make everything else we need by use of the excluded middle:

  \begin{lstlisting}
    /-- ⊥ is for bd_falsum, ≃ for bd_equal, ⟹ for bd_imp, and ∀' for bd_all -/
    /-- we will write ~ for bd_not, ⊓ for bd_and, and infixr ⊔ for bd_or -/
    def bd_not {n} (f : bounded_formula L n) : bounded_formula L n := f ⟹ ⊥
    def bd_and {n} (f₁ f₂ : bounded_formula L n) : bounded_formula L n := ~(f₁ ⟹ ∼f₂)
    def bd_or {n} (f₁ f₂ : bounded_formula L n) : bounded_formula L n := ~f₁ ⟹ f₂
    def bd_biimp {n} (f₁ f₂ : bounded_formula L n) : bounded_formula L n := (f₁ ⟹ f₂) ⊓ (f₂ ⟹ f₁)
    def bd_ex {n} (f : bounded_formula L (n+1)) : bounded_formula L n := ~ (∀' ~ f))
  \end{lstlisting}
\end{dfn}

With this set up we can already write down the sentences that describe rings.
\link{sentences_for_ring_theory}

\begin{lstlisting}
  /-- Assosiativity of addition -/
  def add_assoc : sentence ring_signature :=
  ∀' ∀' ∀' ( (x_ 0 + x_ 1) + x_ 2 ≃ x_ 0 + (x_ 1 + x_ 2) )

  /-- Identity for addition -/
  def add_id : sentence ring_signature := ∀' ( x_ 0 + 0 ≃ x_ 0 )

  /-- Inverse for addition -/
  def add_inv : sentence ring_signature := ∀' ( - x_ 0 + x_ 0 ≃ 0 )

  /-- Commutativity of addition-/
  def add_comm : sentence ring_signature := ∀' ∀' ( x_ 0 + x_ 1 ≃ x_ 1 + x_ 0 )

  /-- Associativity of multiplication -/
  def mul_assoc : sentence ring_signature :=
  ∀' ∀' ∀' ( (x_ 0 * x_ 1) * x_ 2 ≃ x_ 0 * (x_ 1 * x_ 2) )

  /-- Identity of multiplication -/
  def mul_id : sentence ring_signature :=  ∀' ( x_ 0 * 1 ≃ x_ 0 )

  /-- Commutativity of multiplication -/
  def mul_comm : sentence ring_signature := ∀' ∀' ( x_ 0 * x_ 1 ≃ x_ 1 * x_ 0   )

  /-- Distributibity -/
  def add_mul : sentence ring_signature :=
  ∀' ∀' ∀' ( (x_ 0 + x_ 1) * x_ 2 ≃ x_ 0 * x_ 2 + x_ 1 * x_ 2 )\end{lstlisting}

We later collect all of these into one set and call it the \linkto{ring_theory}{theory of rings}.

\subsection{Interpretation of symbols}

In the above we set up a symbol treatment of logic.
In this subsection we try to make these symbols into tangible mathematical objects.

We intend to apply the statement
``any degree two polynomial over our ring has a root''
to a real, usable, tangible ring.
We would like the sort symbol $A$ to be interpreted as the underlying type (set)
for the ring and the function symbols to actually become maps from the ring to itself.

\begin{dfn}[Structures]
    Given a language $\LL$, a $\LL$-\textit{structure} \texttt{M}
    interpreting $\LL$ consists of the following
    \begin{itemize}
      \item An underlying type \texttt{carrier}.
      \item Each function symbol $f : A^{n} \to A$ is interpreted as a
            function that takes an $n$-ary tuple in \texttt{carrier}
            to something in \texttt{carrier}.
      \item Each relation symbol $r \hookr A^{n}$
            is interpreted as a proposition about $n$-ary tuples in \texttt{carrier},
            which can also be viewed as the subset of the set of $n$-ary tuples
            satisfying that proposition.
    \end{itemize}

  \begin{lstlisting}
  structure Structure :=
  (carrier : Type u)
  (fun_map : ∀{n}, L.functions n → dvector carrier n → carrier)
  (rel_map : ∀{n}, L.relations n → dvector carrier n → Prop)\end{lstlisting}

  The \texttt{flypitch} library uses \texttt{dvector A n} for $n$-ary tuples of terms in \texttt{A}.

  Note that rather comically \texttt{Structure} is itself a mathematical structure.
  This is sensible, since \texttt{Structure} is meant to generalize the algebraic
  (and relational) definitions of mathematical structures such as groups and rings.

  Also note that for constant symbols the interpretation has domain empty tuples,
  i.e. only the term \texttt{dvector.nil} as its domain. Hence it is a constant map
  - a term of the interpreted carrier type.
\end{dfn}

The structures in a language will become the models of \linkto{dfn_theory}{theories}.
For example $\Z$ is a structure in the \linkto{dfn_rings}{language of rings},
a model of the \linkto{ring_theory}{theory of rings} but not a model of the theory of fields.
In the language of \linkto{dfn_bin_rel}{binary relations},
$\N$ with the usual ordering $\leq$ is a structure that models of
the theory of partial orders (with the order relation)
but not the theory of equivalence relations (with $\le$).

Before continuing on formalizing ``any degree two polynomial over our ring has a root'',
we stop to make the remark that the collection of all structures in a language forms a category.
To this end we define morphisms of structures.

\begin{dfn}[$\LL$-morphism, $\LL$-embedding]
    \link{category_of_structures}
    The collection of all $\LL$-structures forms a category with objects
    as $\LL$-structures and morphisms as $\LL$-morphisms.

    \begin{lstlisting}
protected structure hom :=
(to_fun : M → N)
(map_fun' : ∀{n} (f : L.functions n) x, to_fun (M.fun_map f x)
  = N.fun_map f (dvector.map to_fun x) . obviously)
(map_rel' : ∀{n} (r : L.relations n) x, M.rel_map r x
  → N.rel_map r (dvector.map to_fun x) . obviously)\end{lstlisting}

    The induced map between the $n$-ary tuples is called \texttt{dvector.map}.
    The above says a morphism is a mathematical structure
    consisting of three pieces of data.
    The first says that we have a functions between the carrier types,
    the second gives a sensible commutative diagram for functions,
    and the last gives a sensible commutative diagram for relations\footnote{
      The way to view relations on a structure categorically is to view it
      as a subobject of the carrier type.}.

    \begin{cd}
      \texttt{dvector M.carrier n}
      \ar[r, "\texttt{M.fun\_map}"] \ar[d, "\texttt{dvector.map to\_fun}", swap]
      & \texttt{M.carrier} \ar[d, "\texttt{to\_fun}"]\\
      \texttt{dvector N.carrier n}
      \ar[r, "\texttt{N.fun\_map}"] & \texttt{N.carrier}\\
        \mmintp{r}
        \ar[hookrightarrow]{r} \ar[d, "\texttt{dvector.map to\_fun}", swap]
        & \texttt{dvector M.carrier n}
        \ar[d, "\texttt{dvector.map to\_fun}"]\\
        \nnintp{r}
        \ar[hookrightarrow]{r} & \texttt{dvector N.carrier n}
      \end{cd}

      The notion of morphisms here will be the same as that of
      morphisms in the algebraic setting.
      For example in the \linkto{dfn_rings}{language of rings},
      preserving interpretation of function symbols says
      the zero is sent to the zero, one is sent to one,
      subtraction, multiplication and addition is preserved.
      In languages that have relation symbols,
      such as that of simple graphs, preserving relations says that
      if the relation holds for terms in the domain,
      then the relation holds for their images.
\end{dfn}

Returning to our objective,
we realize that we need to interpret our degree two polynomial (a term)
is something in our ring. The term

\[ x_{0} x_{3}^{2} + x_{1} x_{3} + x_{2} \]
Should be a map from $4$-tuples from the ring to a value in the ring,
namely, taking $(a, b, c, d)$ to

\[ a c^{2} + b c + d \]

We thus need to figure out how terms in the language interact with
structures in the language.

\begin{dfn}[Interpretation of terms]
    \link{interpretation_terms}
    Given $\LL$-structure $\MM$ and a $\LL$-term $t$ with up to $n$-variables.
    Then we can naturally interpret (a.k.a realize) $t$ in the $\LL$-structure $\MM$ as a
    map from the $n$-tuples of $\MM$ to $\MM$ that
    commutes with the interpretation of function symbols.

    \begin{lstlisting}
@[simp] def realize_bounded_term {M : Structure L} {n} (v : dvector M n) :
  ∀{l} (t : bounded_preterm L n l) (xs : dvector M l), M.carrier
| _ (x_ k)         xs := v.nth k.1 k.2
| _ (bd_func f)    xs := M.fun_map f xs
| _ (bd_app t₁ t₂) xs := realize_bounded_term t₁ (realize_bounded_term t₂ ([])::xs) \end{lstlisting}

    This is defined by induction on (pre)terms.
    When the preterm $t$ is a variable $x_{k}$, we interpret $t$ as a map
    that picks out the $k$-th part of the $n$-tuple \texttt{xs}.
    This is like projecting to the $n$-th axis if the structure looks like an affine line.
    When the term is a function symbol, then we automatically get a map from the
    definition of structures.
    In the last case we are applying a preterm $t_{1}$ to a term $t_{2}$,
    and by induction we already have interpretation of these two preterms
    in our structure, so we compose these in the obvious way.
\end{dfn}

We can finally completely formalize
``any (at most) degree two polynomial has a root''.

\begin{dfn}[Interpretation of formulas]

    Given $\LL$-structure $\MM$ and a $\LL$-formula $f$ with up to $n$-variables.
    Then we can interpret (a.k.a realize or satisfy) $f$ in the $\LL$-structure $\MM$ as a
    proposition about $n$ terms from the carrier type.

    \begin{lstlisting}
@[simp] def realize_bounded_formula {M : Structure L} :
  ∀{n l} (v : dvector M n) (f : bounded_preformula L n l) (xs : dvector M l), Prop
| _ _ v bd_falsum       xs := false
| _ _ v (t₁ ≃ t₂)       xs := realize_bounded_term v t₁ xs = realize_bounded_term v t₂ xs
| _ _ v (bd_rel R)      xs := M.rel_map R xs
| _ _ v (bd_apprel f t) xs := realize_bounded_formula v f (realize_bounded_term v t ([])::xs)
| _ _ v (f₁ ⟹ f₂)       xs := realize_bounded_formula v f₁ xs → realize_bounded_formula v f₂ xs
| _ _ v (∀' f)          xs := ∀(x : M), realize_bounded_formula (x::v) f xs \end{lstlisting}

  This is defined by induction on (pre)formulas.
  \begin{itemize}
    \item[$\vert$] $\bot$ is interpreted as the type theoretic proposition \texttt{false}.
    \item[$\vert$] $t = s$ is interpreted as type theoretic equality of the interpreted terms.
    \item[$\vert$] Interpretation of relation symbols is part of the data of an
          $\LL$-structure (\texttt{rel\_map}).
    \item[$\vert$] If $f$ is a preformula with $n$ free variables that is missing
          $l + 1$ inputs and $t$ is a term with $n$ variables
          then $f$ applied to $t$ can be interpreted using the interpretation of $f$ and
          applied to the interpretation of $t$, both of which are given by induction.
    \item[$\vert$] An implication can be interpreted as a type theoretic implication
          using the inductively given interpretations on each formula.
    \item[$\vert$] $\forall x_{0}, f$ can be interpreted as the type theoretic proposition
          ``for each $x$ in the carrier set $P$'',
          where $P$ is the inductively given interpretation.
  \end{itemize}

  We write $\MM \models f(a)$ to mean ``the realization of $f$ holds in $\MM$ for the terms $a$''.
  We are particularly interested in the case when the formula is a sentence,
  which we denote as $\MM \models f$ (since we need no terms).
  \begin{lstlisting}
@[reducible] def realize_sentence (M : Structure L) (f : sentence L) : Prop :=
realize_bounded_formula ([] : dvector M 0) f ([])\end{lstlisting}
\end{dfn}

Now we are able to express ``this structure in the language of rings has roots
of all degree two polynomials'', using interpretation of sentences.

\subsection{Theories}

%?missing a description

\begin{dfn}[Theory]
  \link{dfn_theory}
  Given a language $\LL$,
  a set of sentences in the language is a theory in that language.
  \begin{lstlisting}
    def Theory := set (sentence L)   \end{lstlisting}
\end{dfn}


\begin{dfn}[Models]
    Given an $\LL$-structure $\MM$ and $\LL$-theory $T$,
    we write $\MM \models T$ and say
    \emph{$\MM$ is a model of $T$} when
    for all sentences $f \in T$ we have $\MM \models f$.

    \begin{lstlisting}
      def all_realize_sentence (M : Structure L) (T : Theory L) := ∀ f, f ∈ T → M ⊨ f \end{lstlisting}
  \end{dfn}

A model of the \linkto{ring_theory}{theory of rings} should be exactly the data of a ring.
Before \linkto{algebraic_objects_iff_models}{converting between algebraic objects
  and their model theoretic counterparts}, so we first write down the theories of
rings, fields, and algebraically closed fields.

\begin{dfn}[The theories of rings, fields and algebraically closed fields]
  \link{ring_theory}
  The theory of rings is just the set of the
  \linkto{sentences_for_ring_theory}{sentences describing a ring}
\begin{lstlisting}
def ring_theory : Theory ring_signature :=
{add_assoc, add_id, add_inv, add_comm, mul_assoc, mul_id, mul_comm, add_mul}\end{lstlisting}

  To make the theory of fields we can add two sentences saying that
  the ring is non-trivial and has multiplicative inverses:
  \begin{lstlisting}
def mul_inv : sentence ring_signature :=
∀' (x_ 1 ≃ 0) ⊔ (∃' x_ 1 * x_ 0 ≃ 1)

def non_triv : sentence ring_signature := ~ (0 ≃ 1)

def field_theory : Theory ring_signature := ring_theory ∪ {mul_inv , non_triv} \end{lstlisting}

  To make the theory of algebraically closed fields we need to express
  ``every non-constant polynomial has a root''.
  We replace this with the equivalent statement ``every monic polynomial has a root''.
  We do this by first making ``generic polynomials''
  in the form of $a_{n+1}x^{n} + \cdots + a_{2}x + a_{1}$,
  then adding $x^{n+1}$ to it, making it a ``generic monic polynomial''.
  The (polynomial) variable $x$ will be represented by the variable \texttt{x\_ 0},
  and the coefficient $a_{k}$ for each $0 < k$ will be represented by the variable
  \texttt{x\_ k}.

  We define generic polynomials of degree (at most) $n$ as bounded ring signature terms
  in $n + 2$ variables by induction on $n$:
  when the degree is $0$, we just take the constant polynomial $x_{1}$
  and supply a proof that $1 < 0 + 2$ (we omit these below using underscores).
  When the degree is $n + 1$, we can take the previous generic polynomial,
  lift it up from a term in $n + 2$ variables to $n + 3$ variables
  (this is \texttt{lift\_succ}),
  then add $x_{n + 2} x_{0}^{n+1}$ at the front.

  \begin{lstlisting}
def gen_poly : Π (n : ℕ), bounded_ring_term (n + 2)
| 0       := x_ ⟨ 1 , _ ⟩
| (n + 1) := (x_ ⟨ n + 2 , _ ⟩) * (npow_rec (n + 1) (x_ ⟨ 0 , _ ⟩))
  + bounded_preterm.lift_succ (gen_poly n)
\end{lstlisting}

  Since the type of terms in the language of rings has notions of
  addition and multiplication (using the function symbols),
  we automatically have a way of taking (natural number) powers.
  This is \texttt{npow\_rec}.

  We proceed to making generic monic polynomials by adding
  $x_{0}^{n+2}$ at the front of the generic polynomial.

  \begin{lstlisting}
def gen_monic_poly (n : ℕ) : bounded_term ring_signature (n + 2) :=
npow_rec (n + 1) (x_ 0) + gen_poly n

/-- ∀ a₁ ⋯ ∀ aₙ, ∃ x₀, (aₙ x₀ⁿ⁻¹ + ⋯ + a₂ x₀+ a₁ = 0) -/
def all_gen_monic_poly_has_root (n : ℕ) : sentence ring_signature :=
fol.bd_alls (n + 1) (∃' gen_monic_poly n ≃ 0) \end{lstlisting}

  We can then easily state ``all generic monic polynomials have a root''.
  The order of the variables is important here:
  the $\exists$ removes the first variable $x_{0}$ in the $n+2$ variable formula
  $\texttt{gen\_monic\_poly} n \simeq 0$, and moves the index of all the
  variables down by $1$, making the remaining expression
  $\exists \texttt{gen\_monic\_poly} n \simeq 0$ a formula in $n+1$ variables.
  The function \texttt{fol.bd\_alls n} then adds $n+1$ many ``foralls''
  in front, leaving us a formula with no free variables, i.e. sentence.

  \begin{lstlisting}
/-- The theory of algebraically closed fields -/
def ACF : Theory ring_signature := field_theory ∪ (set.range all_gen_monic_poly_has_root)\end{lstlisting}

  Since \texttt{all\_gen\_monic\_poly\_has\_root} is a function from the naturals,
  we can take its set theoretic image (called \texttt{set.range}),
  i.e. a sentence for each degree $n$ saying
  ``any monic polynomial of degree $n$ has a root''.
\end{dfn}

\begin{prop}[Algebraic objects $\IFF$ models]
  \link{algebraic_objects_iff_models}
  The following are true
  \begin{itemize}
    \item A type $A$ is a ring (according to lean) if and only if
          $A$ is a structure in the language of rings
          that models the theory of rings.
    \item A type $A$ is a field (according to lean) if and only if
          it is a model of the theory of fields.
    \item A type $A$ is an algebraically closed field (of characteristic p)
          if and only if it is a model of $\ACF_{(p)}$.
  \end{itemize}
  For the purposes of design in lean it is
  more sensible to split each ``if and only if'' into seperate constructions,
  for converting the algebraic objects into their model theoretic counterparts
  and vice versa.
  Although these are very obvious facts on paper,
  converting between them takes a bit of work in \texttt{lean},
  especially for the last,
  where some ground work needs to be done for interpreting \texttt{gen\_monic\_poly}.
\end{prop}

% \begin{dfn}[Consequence]
%     Given a $\LL$-theory $T$
%     and a $\LL$-sentence $\phi$,
%     we say $\phi$ is a consequence of $T$
%     and say $T \model{\LL} \phi$
%     when for all $\LL$-models $\MM$ of $T$,
%     we have $\MM \model{\LL} \phi$.
%     We also write $T \model{\LL} \De$
%     for $\LL$-theories $T$ and $\De$
%     when for every $\phi \in \De$ we have $T \model{\LL} \phi$.
% \end{dfn}

% \begin{ex}[Logical consequence]
%     Let $T$ be a $\LL$-theory and $\phi$ and $\psi$ be $\LL$-sentences.
%     Show that the following are equivalent:
%     \begin{itemize}
%         \item $T \model{\LL} \phi \to \psi$
%         \item $T \model{\LL} \phi$ implies $T \model{\LL} \psi$.
%     \end{itemize}
% \end{ex}

% \begin{dfn}[Consistent theory]
%     \link{consistent}
%     A $\LL$-theory $T$ is consistent if either of the following equivalent
%     definitions hold:
%     \begin{itemize}
%         \item
%             There does not exists a
%             $\LL$-sentence $\phi$ such that
%             $T \model{\LL} \phi$ and $T \model{\LL} \NOT \phi$.
%         \item There exists
%             a $\LL$-model of $T$.
%     \end{itemize}
%     Thus the definition of consistent is intuitively
%     `$T$ does not lead to a contradiction'.
%     A theory $T$ is finitely consistent if all
%     finite subsets of $T$ are consistent.
%     This will turn out to be another equivalent definition,
%     given by the \linkto{compactness}{compactness theorem}.
% \end{dfn}
% \begin{proof}
%     We show that the two definitions are equivalent.
%     \begin{forward}
%         Suppose no model exists.
%         Take $\phi$ to be the $\LL$-sentence $\top$.
%         Hence all $\LL$-models of $T$ satisfy $\top$ and $\bot$
%         (there are none) so
%         $T \model{\LL} \top$ and $T \model{\LL} \bot$.
%     \end{forward}
%     \begin{backward}
%         Suppose $T$ has a $\LL$-model $\MM$
%         and $T \model{\LL} \phi$ and $T \model{\LL} \NOT \phi$.
%         This implies $\MM \model{\LL} \phi$ and $\MM \nodel{\LL} \phi$,
%         a contradiction.
%     \end{backward}
% \end{proof}

% \begin{dfn}[Elementary equivalence]
%     Let $\MM$, $\NN$ be $\LL$-structures.
%     They are elementarily equivalent if for any $\LL$-sentence $\phi$,
%     $\MM \model{\LL} \phi$ if and only if $\NN \model{\LL} \phi$.
%     We write $\MM \equiv_\LL \NN$.
% \end{dfn}

% \begin{dfn}[Maximal and complete theories]
%     \link{equiv_def_completeness_0}
%     A $\LL$-theory $T$ is \textit{maximal} if
%     for any $\LL$-sentence $\phi$,
%     $\phi \in T$ or $\NOT \phi \in T$.

%     $T$ is \textit{complete}
%     when either of the following equivalent
%     definitions hold:
%     \begin{itemize}
%         \item For any $\LL$-sentence $\phi$,
%             $T \model{\LL} \phi$ or
%             $T \model{\LL} \NOT \phi$.
%         \item All models of $T$ are elementarily equivalent.
%     \end{itemize}
%     Note that maximal theories are complete.
% \end{dfn}
% \begin{proof}
%     \begin{forward}
%         Let $\MM$ and $\NN$ be models of $T$
%         and $\phi$ be a $\LL$-sentence.
%         If $T \model{\LL} \phi$ then both satisfy $\phi$.
%         Otherwise $\NOT \phi \in T$ and neither satisfy $\phi$.
%     \end{forward}

%     \begin{backward}
%         If $\phi$ is a $\LL$-sentence then suppose for a contradiction
%         \[T \nodel{\LL} \phi \text{ and } T \nodel{\LL} \NOT \phi\]
%         Then there exist models of $T$
%         such that $\MM \nodel{\LL} \phi$ and $\NN \nodel{\LL} \NOT \phi$.
%         By assumption they are elementarily equivalent and so
%         $\MM \model{\LL} \NOT \phi$ implies $\NN \model{\LL} \NOT \phi$,
%         a contradiction.
%     \end{backward}
% \end{proof}

% \begin{ex}[Not consistent, not complete]
%     \link{not_consequence}
%     Let $T$ be a $\LL$-theory
%     and $\phi$ is a $\LL$-sentence.
%     Show that $T \nodel{\LL} \phi$
%     if and only if $T \cup \set{ \NOT \phi}$ is consistent.
%     Furthermore, $T \nodel{\LL} \NOT \phi$
%     if and only if $T \cup \set{\phi}$ is consistent.

%     Note that by definition for $\LL$-structures and
%     $\LL$-formulas we (classically) have that
%     \[
%         \MM \modelsi \NOT \phi(a) \iff \MM \nodelsi \phi(a)
%     \]
%     Find examples of theories that do not satisfy
%     \[
%         T \modelsi \NOT \phi \iff T \nodelsi \phi
%     \]
% \end{ex}
