In this section we go back to general model theory,
with the goal of proving \linkto{vaught_test}{Vaught's test}.
However, the proof of Vaught's test relies on a (a variant of) the
\linkto{upwards_lowenheim_skolem}{Upwards L\"{o}wenheim-Skolem Theorem}.
It says the following:

\begin{prop}[Upwards L\"{o}wenheim-Skolem]
  \link{upwards_lowenheim_skolem}
  Suppose $L$ is an algebraic language and $T$ is an $L$-theory.
  If $\kappa$ is a sufficiently large cardinal and $T$ has an infinite model,
  then $T$ has a model of size $\kappa$.

  \begin{lstlisting}
theorem has_sized_model_of_has_infinite_model [is_algebraic L] {T : Theory L} {κ : cardinal}
  (hκ : ∀ n, #(L.functions n) ≤ κ) (hωκ : ω ≤ κ) :
  (∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ infinite M) →
  ∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ #M = κ := sorry \end{lstlisting}
\end{prop}

This is often stated in terms of starting with an $L$-structure,
and extending it to a larger $L$-structure,
hence the word ``upward'' in the name.
This can be done using the above by taking $T$ to be the set of
sentences satisfied by the structure.

\subsection{Proof of Vaught's Test}
\link{vaught_proof}

We first apply \linkto{upwards_lowenheim_skolem}{
  Upwards L\"{o}wenheim-Skolem} to prove \linkto{vaught_test}{Vaught's test}.
Recall the statement:

\begin{lstlisting}
lemma is_complete'_of_only_infinite_of_categorical
  [is_algebraic L] {T : Theory L} (M : Structure L) (hM : M ⊨ T)
  (hinf : only_infinite T) {κ : cardinal}
  (hκ : ∀ n, #(L.functions n) ≤ κ) (hωκ : ω ≤ κ) (hcat : categorical κ T) :
  is_complete' T := sorry \end{lstlisting}

\begin{proof}
The proof is by contradiction.
Suppose $T$ is not complete;
this gives us a formula $\phi$ such that
\[ T \nvDash \phi \quad \text{and} \quad T \nvDash \neg \phi \]
which in turn (after unfolding the definition of $T \nvDash \phi$)
gives us two models $M$ and $N$ of $T$ such that
\[ M \nvDash \phi \quad \text{and} \quad N \nvDash \neg \phi \]
our aim is to adjust these to two models of $T$
of cardinality $\kappa$ so that they are isomorphic by categoricity,
but satisfy different sentences.

\begin{lstlisting}
begin
  intro ϕ,
  by_contra hbot,
  simp only [not_or_distrib, not_ssatisfied] at hbot,
  obtain ⟨ ⟨ M , hM0 , hM ⟩ , ⟨ N , hN0 , hN ⟩ ⟩ := hbot,
\end{lstlisting}

We can adjust cardinality using Upwards L\"{o}wenheim-Skolem,
obtaining models of cardinality $\kappa$.
This is why we need $T$ to only have infinite models.
\begin{lstlisting}
  obtain ⟨ M' , hM'0 , hM' , hMcard ⟩ := has_sized_model_of_has_infinite_model hκ hωκ
    ⟨
      M , hM0 , hM ,
      hinf ⟨ M , all_realize_sentence_of_subset hM (set.subset_insert _ _) ⟩
    ⟩,
  obtain ⟨ N' , hN'0 , hN' , hNcard ⟩ := has_sized_model_of_has_infinite_model hκ hωκ
    ⟨
      N , hN0 , hN ,
      hinf ⟨ N , all_realize_sentence_of_subset hN (set.subset_insert _ _) ⟩
    ⟩, \end{lstlisting}

By categoricity, $M$ and $N$ are isomorphic as $L$-structures.
We supply a proof that isomorphic structures satisfy the same
sentences in \texttt{Rings.ToMathlib.fol.lean}.
It follows from a series of proofs by induction on terms and formulas.

\begin{lstlisting}
  have hiso := hcat M' N'
    (all_realize_sentence_of_subset hM' (set.subset_insert _ _))
    (all_realize_sentence_of_subset hN' (set.subset_insert _ _)) hMcard hNcard,
  rw all_realize_sentence_insert at hM' hN',
  rw Language.equiv.realize_sentence _ (classical.choice hiso) at hN',
  exact hN'.1 hM'.1,
end
\end{lstlisting}
\end{proof}

\subsection{Upwards L\"{o}wenheim-Skolem}

Our remaining goal is to prove
\linkto{upwards_lowenheim_skolem}{Upwards L\"{o}wenheim-Skolem}.

\begin{lstlisting}
theorem has_sized_model_of_has_infinite_model [is_algebraic L] {T : Theory L} {κ : cardinal}
  (hκ : ∀ n, #(L.functions n) ≤ κ) (hωκ : ω ≤ κ) :
  (∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ infinite M) →
  ∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ #M = κ := sorry \end{lstlisting}

The idea of the proof is that we want to design a model of the right size
by making a language $L_{2}$ extending $L$ and an $L_{2}$-theory $T_{2}$ extending $T$
(extending in the sense that any $L_{2}$-model of $T_{2}$ reduces down to a $L$-model of $T$),
such that the design of $L_{2}$ and $T_{2}$ guarantee that any model of $T_{2}$ is large enough.
Meanwhile, we design an $L_{2}$-model \texttt{term\_model} of $T_{2}$,
by taking the type of all the $L_{2}$-terms,
and quotienting by equality deduced by $T_{2}$ (this requires $T_{2}$ to be \linkto{henkization}{Henkin}),
guaranteeing that \texttt{term\_model} is small enough
- it will be bounded by the number of terms,
and thus by the number of function symbols in the language.

\subsubsection{Adding distinct constant symbols}

Suppose we have a language $L$ and a consistent theory $T$ that has
an infinite model $M$, as well as an infinite cardinal $\kappa$.
Our first goal is to make a consistent theory $T_\kappa$
in a language $L_{\kappa}$ such that any model of $T_{\kappa}$
is size at least $\kappa$.

\textit{The language extended to have $\kappa$ many symbols:}
For design reasons it is convenient to work generally.
We will do the following
\begin{enumerate}
  \item Define the type of language morphisms $\texttt{L1} \to^{L} \texttt{L2}$
  \item Define the sum of two languages \texttt{L1.sum L2}
        and the language morphisms into the sum.
  \item Define the language that has constant symbols indexed by a type $\al$,
        called \texttt{of\_constants $\al$}.
        In our situation we will take $\al$ to be \texttt{$\ka$.out},
        which is a type of cardinality $\kappa$ (by the axiom of choice)
  \item Define the theory \texttt{distinct\_constants $\al$}
        in the language \texttt{of\_constants $\al$}
        that consists of $\texttt{a} \ne \texttt{b}$
        for each pair of distinct terms \texttt{a b : $\al$}.
  \item Define the induced $\texttt{L2}$-theory
        from a morphism of languages $\texttt{L1} \to^{L} \texttt{L2}$ and
        an \texttt{L1}-theory
  \item Make the sum of the languages $L$ (from the above hypotheses)
        and \texttt{of\_constants $\al$}.
        We are interested in taking the union of the induced theory from \texttt{T}
        and the induced theory from
        \texttt{distinct\_constants $\al$}.
        We call this theory \texttt{union\_add\_distinct\_constants T $\al$}
  \item Show that \texttt{union\_add\_distinct\_constants T $\al$} is consistent
        when $T$ has an infinite model
\end{enumerate}

$(1)$ A morphism of languages consists of a map on function symbols
and a map on relation symbols (for each arity).
\begin{lstlisting}
structure Lhom (L1 L2 : Language) :=
(on_function : ∀{n}, L1.functions n → L2.functions n)
(on_relation : ∀{n}, L1.relations n → L2.relations n) \end{lstlisting}
We denote this type by $\texttt{L1} \to^{L} \texttt{L2}$.

\link{language_sum_dfn}
$(2)$ The sum of two languages takes two languages and makes the
disjoint sum of the function symbols and relation symbols of
each arity.
\begin{lstlisting}
def sum (L1 L2 : Language) : Language :=
⟨λn, L1.functions n ⊕ L2.functions n, λ n, L1.relations n ⊕ L2.relations n⟩ \end{lstlisting}
The obvious morphisms into the sum are from the maps into the disjoint
sum of types
\begin{lstlisting}
def sum_inl {L L' : Language} : L →ᴸ L.sum L' :=
⟨λn, sum.inl, λ n, sum.inl⟩

def sum_inr {L L' : Language} : L' →ᴸ L.sum L' :=
⟨λn, sum.inr, λ n, sum.inr⟩ \end{lstlisting}

$(3)$ \texttt{of\_constants $\al$} sets $\al$ as the set of function symbols
of arity $0$, and makes no other function or relation symbols.
\begin{lstlisting}
def of_constants (α : Type*) : Language :=
{ functions := λ n, match n with | 0 := α | (n+1) := pempty end,
  relations := λ _, pempty } \end{lstlisting}

$(4)$ We first make a function from the product $\al \times \al$ to
the set of sentences, that takes $(x_1,x_2)$ and returns the sentence
$x_{1} \ne x_{2}$.
Then the image of the complement of the diagonal in $\al \times \al$
is the theory we want.

\begin{lstlisting}
def distinct_constants_aux (x : α × α) : sentence (Language.of_constants α) :=
∼ (bd_const x.fst ≃ bd_const x.snd)

def distinct_constants : Theory (Language.of_constants α) :=
set.image (distinct_constants_aux _) { x : α × α | x.fst ≠ x.snd } \end{lstlisting}

\link{induced_theory_dfn}
$(5)$ The theory induced by a language morphism is constructed by
taking image of the induced map from \texttt{L1}-sentences
to \texttt{L2}-sentences.
This in turn is a special case of the induced map on bounded formulas,
which is made by induction on bounded formulas and bounded terms.
We don't go through the details of this;
the code is from \texttt{flypitch} and can be found in
\texttt{language\_extension.lean}.

$(6)$ The theory we are interested in is the latter of the following
\begin{lstlisting}
def add_distinct_constants : Theory $ L.sum (Language.of_constants α) :=
Theory_induced Lhom.sum_inr $ distinct_constants _

def union_add_distinct_constants (T : Theory L) (α : Type u) :=
(Theory_induced Lhom.sum_inl T : Theory $ L.sum (of_constants α)) ∪ add_distinct_constants α \end{lstlisting}
It combines the induced theories from the maps into the sum,
starting with the theory $T$ we want to build a $\kappa$-sized
model for and adding $\kappa$ many symbols to it.

$(7)$ Suppose $T$ is a theory with an infinite model $M$ and $\al$ is a type.
We want to show

\begin{lstlisting}
lemma is_consistent_union_add_distinct_constants {T : Theory L} (α : Type u)
  {M : Structure L} (hMinf : infinite M) (hMT : M ⊨ T):
  is_consistent $ union_add_distinct_constants T α
\end{lstlisting}

\linkto{compactness_consistency}{Compactness} tells us we only
need to show that a finite subset of $\al$ is consistent.
So we can take our original model $M$ and realize finitely many
distinct constant symbols from $\al$ in $M$ as distinct elements,
as $M$ is infinite.
To this end let's suppose we have
\[\texttt{Tfin} \cup \texttt{con\_fin} = \texttt{fs}\]
where \texttt{Tfin} and \texttt{con\_fin} are respectively
finite subsets of $T$ and $\texttt{add\_distinct\_constants} \al$.

\begin{lstlisting}
  rw compactness',
  intros fs hfsTα,
  rw model_existence,
  obtain ⟨Tfin, con_fin, hfs, hTfin, h_con_fin⟩ := finset.subset_union_elim hfsTα, \end{lstlisting}

We need to pick out all the constant symbols that appeared in
\texttt{con\_fin} (the details of which we will not go through).
We call the set of these constant symbols $\al\texttt{\_fin}$,
and note that it must be finite,
hence has an injection into $M$ (by choice).



\begin{lstlisting}
  set αfin : finset α := constants_appearing_in (of_constants.preimage con_fin)
    with hαfin,
  let on_αfin : αfin ↪ M := classical.choice ((cardinal.le_def αfin M).1
    (le_of_lt $ cardinal.finset_lt_infinite hMinf)),
\end{lstlisting}

We can extend this to a full realization of $M$ has a structure in the
language \texttt{L.sum (of\_constants $\al$)}.
Since $M$ is non-empty, we can send every symbol not in $\al\texttt{\_fin}$
to some arbitrary element (by choice).
To instantiate the goal with this structure, we make a general function

\begin{lstlisting}
def sum_Structure : Structure (L.sum (of_constants α)) :=
{ carrier := S,
  fun_map := λ n f, sum.cases_on f (λ f, S.fun_map f) $ of_constants.fun_map c,
  rel_map := λ n r, sum.cases_on r (λ r, S.rel_map r) pempty.elim } \end{lstlisting}

which takes a map interpreting the extra constant symbols
and produces a structure in the extended language.

\begin{lstlisting}
  have hM0 : nonempty M := infinite.nonempty _,
  set c : α → M :=
    λ x, dite (x ∈ αfin) (λ h, on_αfin ⟨x,h⟩) (λ _, classical.choice hM0) with hc,
  refine ⟨ Language.of_constants.sum_Structure c , hM0 , _ ⟩, \end{lstlisting}

It remains to show that this structure is a model of the theory \texttt{fs}.
That it models a the subset of $T$ is tedious to show but clear\footnote{
  The lemmas used to show that \texttt{sum\_Structure c} models the induced
  theory could be generalized to say that if the
  interpretation maps agree upon restriction to the smaller language
  then the extended structure will model the induced theory. }.

\begin{lstlisting}
  rw [← hfs, finset.coe_union, all_realize_sentence_union],
  split,
  { apply all_realize_sentence_of_subset _ hTfin,
    apply Language.of_constants.sum_Structure_Theory_induced hMT },
  { sorry }, \end{lstlisting}

That it models \texttt{con\_fin} requires a lot of rewriting but
boils down to the fact that the realization of constant symbols
was an injection when restricted to the symbols from \texttt{con\_fin}.
We omit the rest of the code.

\subsubsection{\texttt{term\_model}}

Recalling that our goal is to construct a model of a fixed cardinality,
we can move on to designing our model.
In \texttt{flypitch} this construction is called \texttt{term\_model}.
In brief, given an $L$-theory $T$, the structure consists of:
\begin{itemize}
  \item The collection of $L$-terms with no variables (\texttt{closed\_term L})
        up to $T$-equality as the
        carrier type for the structure.
        Formally this is the quotient by the relation
        \[ t \sim s \iff T \vDash t = s \]
  \item To interpret function symbols, we need to take a
        symbol $f$ of arity $n$ and a \texttt{dvector} of closed terms
        (up to equivalence) and return (the equivalence class of) a closed term.
        The term we pick is naturally $f$
        applied to the previous $n$ closed terms (using \texttt{bd\_apps}).
        One must check that this is respects the equivalence relation.
  \item Similarly to interpret relation symbols, we need to take a
        symbol $r$ of arity $n$ and a \texttt{dvector} of closed terms.
        The term we pick is $r$ applied to the previous $n$ closed terms
        (using \texttt{bd\_apps\_rel}).
\end{itemize}

Of course this construction is not always going to give a model of the
theory, since there are theories that have no models.
However, in suitable conditions we will have that for any $L$-sentence $\phi$
\[
  T \vDash \phi \quad \text{ if and only if } \quad
  \texttt{term\_model T} \vDash \phi
\]
These conditions are
\begin{itemize}
  \item $T$ is a \linkto{is_complete_theory}{maximal complete theory}
        (called \texttt{is\_complete} in \texttt{flypitch}).
  \item The theory $T$ is Henkin, or has the witness property,
        or $L$ has enough constant symbols with respect to $T$:
\begin{lstlisting}
def has_enough_constants (T : Theory L) :=
∃(C : Π(f : bounded_formula L 1), L.constants),
  ∀(f : bounded_formula L 1), T ⊨ ∃' f ⟹ f[bd_const (C f)/0] \end{lstlisting}
        This says for each formula with one free-variable
        there is a constant symbol that would witness the
        existence of a term satisfying the formula in any model.
\end{itemize}

We demonstrate the role of these conditions in the following.
To prove
\[ T \vDash \phi \quad \text{ if and only if } \quad
  \texttt{term\_model T} \vDash \phi \]
for all sentences $\phi$, we induct on $\phi$.
For backwards direction on the $\forall$ case
we are showing that
\[ \texttt{term\_model T} \vDash \forall x, \phi \quad \text{ implies }
  \quad T \vDash \forall x, \phi \]

Assume $\texttt{term\_model} \vDash \forall x, \phi$.
By \textbf{maximality} either $T \vDash \forall x, \phi$ or
$T \vDash \exists x, \neg \phi$.
It suffices to refute the latter case.
Suppose $T \vDash \exists x, \neg \phi$.
As $T$ is \textbf{Henkin},
there is some constant symbol $c$ such that $T \vDash \neg \phi_{c}$
where $\phi_{c}$ is the sentence with $x$ replaced for $c$.
Since $T$ is \textbf{consistent} this implies $T \nvDash \phi_{c}$,
and by the induction hypothesis $\texttt{term\_model} \nvDash \phi_{c}$.
However, $c$ is realized as some \texttt{a : term\_model},
thus by our assumption $\texttt{term\_model} \vDash \phi(a)$,
and a bit of work shows $\texttt{term\_model} \vDash \phi_{c}$,
a contradiction.

\subsubsection{Henkinization}

The above indicates we must extend to a further language and a further theory
in the language, such that the extended theory is maximally consistent and Henkin.
We start with a consistent theory $T_{\kappa}$
(which in our situation is the theory with extra $\kappa$ constant symbols).
The first thing to do is to make it Henkin, ensuring it is still consistent,
we call the language we extended to $L_{H}$ and the new $L_{H}$-theory $T_{H}$.
Secondly, we throw in enough formulas to make it maximally consistent,
and call this new theory $T_{m}$.
All of this is done in \texttt{flypitch} and can mostly be found in \texttt{henkin.lean}.
An overview follows.

The second step can be done in either of the following ways:
\begin{itemize}
  \item Since the theory $T_{H}$ is consistent, it has a $L_{H}$-model,
        hence the set $T_{m}$ of $L_{H}$-sentences satisfied by the $L_{H}$-model is a
        $L_{H}$-theory extending $T_{H}$.
        It is maximal by the law of the excluded middle:
        the model $M$ either satisfies a formula or not,
        hence
        \[ M \vDash \phi \quad \text{ or } \quad M \vDash \neg \phi \]
        $T_{m}$ is consistent since $M$ is a model.\footnote{Note that
          $T \nvDash \phi$ does not imply $T \vDash \NOT \phi$ in general.
          This implication holds if and only if $T$ is complete.
          Thus we needed to appeal to a model in the above.}
  \item We can use Zorn's lemma: the set of consistent $L_{H}$-theories extending
        $T_{H}$ is non-empty as $T$ is in the set.
        Any chain of consistent $L_{H}$-theories extending $T_{H}$ is bounded
        above by a consistent theory since we can take the union of them,
        and check consistency using \linkto{compactness_consistency}{compactness}.
        One can check that this set theoretic maximality corresponds to
        the definition of a maximal consistent theory.
        Consistency is given for free by Zorn.
\end{itemize}
In the \texttt{flypitch} project, the setup of first order logic
syntax rather than its semantics means the Zorn approach is most natural.

The first step requires recursively defined languages extending one another
\[ L_{0} \to^{L} L_{1} \to^{L} \dots \]
and theories in each language such that the induced theories
at each level are sub-theories of the next

\[\begin{tikzcd}[row sep = tiny]
	{\texttt{T}_0} && {\texttt{induce T}_0 \subs \texttt{T}_1} \\
	{\texttt{Theory L}_0} && {\texttt{Theory L}_1}
	\arrow["{\texttt{induce}}", from=2-1, to=2-3]
	\arrow[shorten <=17pt, shorten >=2pt, maps to, from=1-1, to=1-3]
\end{tikzcd}\]

Specifically, the inductive step is
\begin{lstlisting}
inductive henkin_language_functions (L : Language.{u}) : ℕ → Type u
| inc : ∀ {n}, L.functions n → henkin_language_functions n
| wit : bounded_formula L 1 → henkin_language_functions 0 \end{lstlisting}
At each step we make a language $L_{i+1}$
inheriting all the function symbols from $L_{i}$ via \texttt{inc},
and for each $L_{i}$-formula $\phi$ with one free variable, we introduce a
new constant symbol \texttt{wit $\phi$} for that specific formula.

Then we can then make the new $L_{i+1}$-theory $T_{i+1}$ by taking the induced theory of
$T_{i}$ and adding a new sentence $\exists \phi \implies \phi(\texttt{wit } \phi)$
(as an induced $L_{i+1}$-sentence) for each $L_{i}$-formula $\phi$ with one free variable.

\begin{lstlisting}
def wit_property {L : Language} (f : bounded_formula L 1) (c : L.constants) :
  sentence L := (∃'f) ⟹ f[bd_const c/0]

def henkin_theory_step {L} (T : Theory L) : Theory $ henkin_language_step L :=
Theory_induced henkin_language_inclusion T ∪
(λ f : bounded_formula L 1,
  wit_property (henkin_language_inclusion.on_bounded_formula f) (wit' f)) '' (set.univ : set $ bounded_formula L 1)
\end{lstlisting}

Each $T_{i+1}$ is consistent since $T_{i}$ is consistent;
a model of $T_{i}$ will be a model of the new theory.
Indeed if \texttt{a : M} realizes $\exists \phi$
then we can interpret $\texttt{wit } \phi$ as \texttt{a},
satisfying the new sentences in $T_{i+1}$.

Hence we can take the colimit of these languages \texttt{L\_infty}
(which amounts to a union of the function symbols in set theory)
\[\begin{tikzcd}
	{\texttt{L}_0} & {\texttt{L}_1} & \cdots \\
	&& {\texttt{L\_infty}}
	\arrow[from=1-1, to=1-2]
	\arrow[from=1-2, to=1-3]
	\arrow[from=1-1, to=2-3]
	\arrow[from=1-2, to=2-3]
	\arrow[dotted, from=1-3, to=2-3]
\end{tikzcd}\]
and take the union of the induced theories in \texttt{L\_infty}
to be our desired theory \texttt{T\_infty}.

\begin{itemize}
  \item
        \texttt{T\_infty} is consistent since it is finitely consistent
        (at each step the new theory $T_{i+1}$ is consistent
        and since the theories form a chain,
        any finite subset will be a subset of some $T_{i}$).
  \item
        \texttt{T\_infty} is Henkin since any \texttt{L\_infty}-formula in one free variable
        is an induced formula from some $L_{i}$, which is witnessed by a constant symbol
        from $L_{i+1}$ according to theory $T_{i+1}$, which is embedded in \texttt{T\_infty}.
\end{itemize}

Both of these steps are combined together as

\begin{lstlisting}
def completion_of_henkinization {L} {T : Theory L} (hT : is_consistent T) : Theory (henkin_language) := sorry
\end{lstlisting}

We are now ready to prove Upwards L\"{o}wenheim-Skolem
sans the part about cardinality.

\begin{lstlisting}
theorem has_sized_model_of_has_infinite_model [is_algebraic L] {T : Theory L} {κ : cardinal}
  (hκ : ∀ n, #(L.functions n) ≤ κ) (hωκ : ω ≤ κ) :
  (∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ infinite M) →
  ∃ M : Structure L, nonempty M ∧ M ⊨ T ∧ #M = κ :=
begin
  rintro ⟨ M , hM0, hMT, hMinf ⟩, \end{lstlisting}

Supposing $T$ is consistent, we can come up with a model $M$.
We can then add $\kappa$ many constant symbols to form $L_\kappa$
and ensure they are all distinct in theory $T_\kappa$,
which is consistent by our work above.
\begin{lstlisting}
  set Tκ := union_add_distinct_constants T κ.out,
  have hTκ_consis := is_consistent_union_add_distinct_constants κ.out hMinf hMT, \end{lstlisting}
We Henkinize $T_\kappa$ then take the maximal consistent $L_{2}$-theory $T_{2}$
extending that (where $L_{2} := \texttt{henkin\_language}$).
We know that this is consistent, maximal and Henkin,
hence \texttt{term\_model T2} satisfies exactly the formulas
that appear in $T_{2}$.
However, we need to take the \texttt{reduct} of \texttt{term\_model T2},
since we only want an $L$-structure which models the $L$-theory $T$.
The reduct simply takes the original carrier set and realizes symbols
as the realization of their images in the extended language.
This is denoted \texttt{M[[ $\iota : L_{0} \to^{L} L_{1}$ ]]}, where $M$ is
an $L_{1}$-structure.
We first take the reduct to $L_{\kappa}$, then down to $L$.

\begin{lstlisting}
  set T2 := completion_of_henkinization hTκ_consis,
  use (term_model T2)[[ henkin_language_over ]]
    [[(Lhom.sum_inl : L →ᴸ L.sum (of_constants κ.out))]], \end{lstlisting}

It remains to show that this reduct is non-empty and a model of $T$,
which follows from general theory about reducts and API for
\texttt{completion\_of\_henkinization} and \texttt{term\_model}.

\begin{lstlisting}
  split,
  -- the reduction of a non-empty model is non-empty
  { apply fol.nonempty_term_model, exact completion_of_henkinization_is_henkin _, },
  split,
  -- this reduction models T
  { apply Lhom.reduct_Theory_induced Lhom.sum.is_injective_inl,
    have h := reduct_of_complete_henkinization_models_T hTκ_consis,
    simp only [all_realize_sentence_union] at h,
    exact h.1 },
  sorry, \end{lstlisting}

The final goal is finding the cardinality of \texttt{term\_model},
which we explore in the next subsection.

\subsubsection{Cardinality of \texttt{term\_model}}

Our goal is
\begin{lstlisting}
⊢ # ↥(term_model T2[[henkin_language_over]][[Lhom.sum_inl]]) = κ \end{lstlisting}
which says the cardinality of the carrier type of the
reduct of \texttt{term\_model T2} to $L$ is $\kappa$.
We first show $(\ge)$
\begin{lstlisting}
⊢ # κ ≤ ↥(term_model T2[[henkin_language_over]][[Lhom.sum_inl]]) \end{lstlisting}
To show this, it suffices to show
\begin{itemize}
  \item The carrier type of any \texttt{(Language.of\_constants $\al$)}-model of
        \texttt{distinct\_constants $\al$} is at least size $\# \al$
  \item The reduct of \texttt{term\_model} to
        \texttt{Language.of\_constants $\kappa$.out} is a model of
        \texttt{distinct\_constants $\kappa$.out}
  \item The carrier type in the goal (the reduct of \texttt{term\_model} to \texttt{L})
        equals to the carrier type of the reduct of \texttt{term\_model} to
        \texttt{Language.of\_constants $\al$}
\end{itemize}

The first point follows from our definition of \texttt{distinct\_constants}:
Suppose $M$ is a (\texttt{Language.of\_constants $\al$})-model of
\texttt{distinct\_constants $\al$}.
Then to show that $\# \al \le \# M$ it suffices to show that the function
taking any $a : \al$ to its realization in $M$ is an injection.
\begin{lstlisting}
lemma all_realize_sentence_distinct_constants (M : Structure _) (hM : M ⊨ distinct_constants α) : #α ≤ #M :=
begin
  apply @cardinal.mk_le_of_injective _ _ (λ a, M.constants a),
  intros x y hfxy, \end{lstlisting}
Let two terms $x$ and $y : \al$ be equal upon realization in $M$,
and suppose for a contradiction $x \ne y$.
Then by definition the sentence $x \ne y$ is in
of the theory \texttt{distinct\_constants $/al$}, so
$x$ and $y$ are not equal upon realization in $M$,
a model of \texttt{distinct\_constants}.
\begin{lstlisting}
  by_contra' hxy,
  rw all_realize_sentence_image at hM,
  apply hM ⟨x,y⟩ hxy,
  simp only [Structure.constants] at hfxy,
  simp [bd_const, hfxy],
end \end{lstlisting}

The second point follows from the fact that
for any injective morphism of languages,
the reduct of models of induced theories are models of the original theories.

The third point is just by simplification, which I have extracted for clarity.
Putting the three parts together we have the inequality
\begin{lstlisting}
    have hle : #κ.out ≤ #((term_model T2)[[henkin_language_over]]
             [[(Lhom.sum_inr : _ →ᴸ L.sum (of_constants κ.out))]]),
    { apply all_realize_sentence_distinct_constants,
      apply Lhom.reduct_Theory_induced Lhom.sum.is_injective_inr,
      have h := reduct_of_complete_henkinization_models_T hTκ_consis,
      simp only [all_realize_sentence_union] at h,
      exact h.2 },
    { simp only [fol.Lhom.reduct_coe, cardinal.mk_out] at hle ⊢,
      exact hle } \end{lstlisting}

Now we show $(\le)$.
\begin{lstlisting}
⊢ # ↥(term_model T2[[henkin_language_over]][[Lhom.sum_inl]]) ≤ κ \end{lstlisting}
This will require opening up the definition of \texttt{term\_model}.
We know that \texttt{term\_model T2} is a quotient of the type of closed
terms in the language \texttt{henkin\_language}, thus

\begin{lstlisting}
lemma card_le_closed_term : #(term_model T) ≤ #(closed_term L) :=
cardinal.mk_le_of_surjective quotient.surjective_quotient_mk' \end{lstlisting}

We see that we must investigate the cardinality of
closed terms, or more generally terms and formulas.
Since intuitively induction on terms and formulas
produces well-founded trees stemming from formula (and relation) symbols,
we should be able to bound \texttt{bounded\_preterm L n l}
and \texttt{bounded\_formula L n} by the collection of function symbols in $L$.
More precisely,
\begin{lstlisting}
lemma bounded_preterm_le_functions {l} : #(bounded_preterm L n l) ≤
  max (cardinal.sum (λ n : ulift.{u} (ℕ), #(L.functions n.down))) ω := sorry

lemma bounded_formula_le_functions [is_algebraic L] {n} : #(bounded_formula L n) ≤
  max (cardinal.sum (λ n : ulift.{u} ℕ, #(L.functions n.down))) ω := sorry \end{lstlisting}

We will prove these facts in a \linkto{cardinality_lemmas}{later section}.
For now, we conclude

\begin{lstlisting}
lemma card_le_functions : #(term_model T) ≤
  max (cardinal.sum (λ n : ulift.{u} (ℕ), #(L.functions n.down))) ω :=
calc #(term_model T)
      ≤ #(closed_term L) : card_le_closed_term T
  ... ≤ max (cardinal.sum (λ n : ulift.{u} ℕ, #(L.functions n.down))) ω :
    cardinal.bounded_preterm_le_functions _ \end{lstlisting}

We can then extract the condition for which \texttt{term\_model} is
less than or equal to an infinite cardinal by simple cardinal
arithmetic: it suffices that for each natural $n$,
the number of function symbols with arity $n$ is bounded by $\ka$.

\begin{lstlisting}

lemma card_le_cardinal {κ : cardinal.{u}} (hωκ : ω ≤ κ)
  (hκ : ∀ n : ulift.{u} ℕ, #(L.functions n.down) ≤ κ) : #(term_model T) ≤ κ :=
begin
  apply le_trans (card_le_functions T),
  apply max_le _ hωκ,
  apply le_trans (cardinal.sum_le_sup (λ n : ulift.{u} ℕ, #(L.functions n.down))),
  apply le_trans (cardinal.mul_le_max _ _),
  apply max_le _ hωκ,
  apply max_le,
  { simp [hωκ] },
  { rw cardinal.sup_le, exact hκ },
end \end{lstlisting}

Now we can continue with our proof:

\begin{lstlisting}
  apply term_model.card_le_cardinal T2 hωκ,
  intro n, \end{lstlisting}

Our goal looks like
\begin{lstlisting}
⊢ # (henkin_language.functions n.down) ≤ κ \end{lstlisting}

We must investigate how many function symbols we have added
during Henkinization.
Since Henkinization is an inductive process adding
$L$-formulas-with-one-free-variable many constant symbols at
each step, this must be at most the collection of all function symbols
or $\om$.
Again we extract a lemma,
saying that if an infinite cardinal $\kappa$ bounds the
function symbols in $L$ above then
$\kappa$ bounds the function symbols of the henkinization of $L$
above as well.

\begin{lstlisting}
lemma henkin_language_le_cardinal [is_algebraic L] {T : Theory L}
  {hconsis : is_consistent T} (hωκ : ω ≤ κ)
  (hLκ : ∀ n, # (L.functions n) ≤ κ) (n : ℕ) :
  # ((@henkin_language _ _ hconsis).functions n) ≤ κ := sorry \end{lstlisting}

We also prove this lemma in the \linkto{henkinization_cardinality}{next subsection}.
Note that we assume the language is algebraic for simplicity.
This condition can be dropped but saves a bit of work for our use case.
Indeed in our use case, the sum of algebraic languages is algebraic,
$L$ is assumed to be algebraic, and \texttt{of\_constants $\ka$.out}
is clearly algebraic.

Proceeding with the proof, we simply need to show that
for each natural $m$
the language that we Henkinized has at most $\ka$ many function symbols
with arity $m$.
Since the sum of languages takes the disjoint sum of function symbols,
the cardinality of the sum of function symbols is just the sum of
the cardinalities of function symbols from each language.

\begin{lstlisting}
  apply henkin_language_le_cardinal hωκ,
  { intro m,  -- the bound on function symbols
    simp only [Language.sum, cardinal.mk_sum, cardinal.lift_id], \end{lstlisting}

The goal is now

\begin{lstlisting}
⊢ # (L.functions m) + # ((of_constants κ.out).functions m) ≤ κ \end{lstlisting}

By cardinal arithmetic it suffices to show that both parts of the
sum are bounded by $\kappa$.
The left is bounded by $\kappa$ {by assumption}.
The right is equal to $\kappa$ when $m = 0$ by definition of
\texttt{of\_constants}, and otherwise is empty.
Hence the sum is bounded by $\kappa$.

\begin{lstlisting}
    apply le_trans (cardinal.add_le_max _ _),
    apply max_le _ hωκ,
    apply max_le,
    { apply hκ },
    { cases m,
      { simp [of_constants] },
      { simp [of_constants] } } \end{lstlisting}

Hence we have completed the proof of Upwards L\"{o}wenheim-Skolem.

\subsection{Cardinality lemmas}

\link{cardinality_lemmas}
\subsubsection{Terms}

In this subsection we prove that the number of preterms is bounded by
the number of function symbols in the language.

\begin{lstlisting}
lemma bounded_preterm_le_functions {l} : #(bounded_preterm L n l) ≤
  max (cardinal.sum (λ n : ulift.{u} (ℕ), #(L.functions n.down))) ω := sorry \end{lstlisting}

There should be many approaches to this problem.
Mine was to note that preterms can be interpreted
the collection of lists of preterm symbols that satisfy certain rules.
Then the list of all these symbols can be easily bounded above.
For example, the term \texttt{0 + (1 * x\_0)}
will be written as a list of symbols
(the natural numbers for \texttt{app} will be explained later)
\begin{lstlisting}
  [app,10]
    ++ ([app,1]
      ++ [func +]
      ++ ([app,4] ++ ([app,1] ++ [func *] ++ [func 1]) ++ [var 0]))
    ++ [func 0]
\end{lstlisting}

The \textbf{preterm symbols} can be made as an inductive type
\begin{lstlisting}
inductive preterm_symbol (L : Language) : Type u
| nat : ℕ → preterm_symbol
| var : Π {l}, fin l → preterm_symbol
| func : Π {l}, L.functions l → preterm_symbol
| app : preterm_symbol \end{lstlisting}

Then we \textbf{inject} \texttt{bounded\_preterm L n l}
into the collection of lists of preterm symbols.

\begin{lstlisting}
def preterm_symbol_of_preterm {n} : ∀ {l},
  bounded_preterm L n l → list (preterm_symbol L)
| _ (&k)         := [ preterm_symbol.var k ]
| l (bd_func f)  := [ preterm_symbol.func f ]
| l (bd_app t s) := [ preterm_symbol.app,
  preterm_symbol.nat (preterm_symbol_of_preterm t).length ]
  ++ preterm_symbol_of_preterm t ++ preterm_symbol_of_preterm s
 \end{lstlisting}

The choice of each list is designed to capture all
the pieces of data that went into constructing the term.
If the term was built as a variable \texttt{\&k}
then we only need to include the data that
it was built as a variable symbol and that it used bounded natural $k$,
so we take the list consisting of only
the preterm symbol \texttt{[ preterm\_symbol.var k ]}.
The case for a function symbol is similar.
More interestingly, when the preterm is built from
applying a preterm \texttt{t : bounded\_preterm L n (l + 1)}
to a preterm \texttt{s : bounded\_preterm L n 0},
we preserve the data of $t$ and $s$ by appending their
inductively given lists to the end of everything else we need.
It turns out that preserving the length of the list from $t$
is important for showing injectivity.

To \textbf{show injectivity} of the above we induct on $L$-terms $x$ and $y$.
There are $9$ cases to work on since there are $3$ cases for $x$ and $y$
respectively.

\begin{lstlisting}
lemma preterm_symbol_of_preterm_injective {l} :
  function.injective (@preterm_symbol_of_preterm L n l) :=
begin
  intros x,
  induction x with k _ _ _ tx sx htx hsx,
  { intro y,
    cases y,
    { intro h, simp only [...] at h, subst h },
    { intro h, cases h },
    { intro h, cases h } },
  { intro y,
    cases y,
    { intro h, cases h },
    { intro h, simp only [...] at h, subst h },
    { intro h, cases h } },
  { intro y,
    cases y with _ _ _ _ ty sy,
    { intro h, cases h },
    { intro h, cases h },
    { intro h, simp only [...] at h,
      obtain ⟨ ht , hs ⟩ := list.append_inj h.2 h.1,
      congr, { exact htx ht }, { exact hsx hs } } },
end \end{lstlisting}

The cases where $x$ and $y$ are not built by the same constructor
are easy to eliminate, since \texttt{no\_confusion}
for lists tells us two equal lists must have equal elements in the lists,
and \texttt{no\_confusion} for \texttt{preterm\_symbol} tells us
two equal preterm symbols must have come from the same constructor,
which yields a contradiction in each case.
This argument is hidden by the tactics \texttt{intro h, cases h},
where $h$ is the assumption that $x$ and $y$
make equal lists of preterm symbols.

The remaining cases: when both are variable symbols or both are function symbols
then we are assuming two lists with a single element are equal,
since the elements are the same constructor applied to some variable,
those variables must be equal by \texttt{no\_confusion} for
\texttt{preterm\_symbol}.
We thus have that $x = y$.
In the case when $x$ and $y$ are both applications,
we can use \texttt{no\_confusion} for lists and
apply injectivity of \texttt{list.append}
to deduce each part of the list is equal and apply the induction hypothesis.
Injectivity of \texttt{list.append} uses equality of lengths of the
sublists, which is why we included that data in our definition of
\texttt{preterm\_symbol\_of\_preterm}.

Now that we have an injection into \texttt{list (preterm\_symbol L)}
we should \textbf{compute the cardinality} of \texttt{preterm\_symbol L},
which will determine the cardinality of lists of them.
We make a type equivalent to \texttt{preterm\_symbol L}:

\begin{lstlisting}
def preterm_symbol_equiv_fin_sum_formula_sum_nat :
  (preterm_symbol L) ≃
    (Σ l : ulift.{u} ℕ, ulift.{u} (fin l.down)) ⊕ (Σ l : ulift.{u} ℕ, L.functions l.down) ⊕ ℕ := ... \end{lstlisting}

This equivalence of types is obvious.
Equivalent types have the same cardinality, so
we can just compute the cardinality of the latter,
for which there is plenty of API.

We are ready to complete the lemma.
By the injection above we have the first inequality:
\begin{lstlisting}
lemma bounded_preterm_le_functions {l} : #(bounded_preterm L n l) ≤
  max (cardinal.sum (λ n : ulift.{u} (ℕ), #(L.functions n.down))) ω :=
calc #(bounded_preterm L n l) ≤ # (list (preterm_symbol L)) :
    cardinal.mk_le_of_injective (@preterm_symbol_of_preterm_injective L n l)
\end{lstlisting}
For an infinite type $\al$, $\# \al = \# \texttt{list } \al$.
Then replacing the cardinality along the equivalence above,
and going through some simple cardinal arithmetic proves the final inequality.
\begin{lstlisting}
  ... = # (preterm_symbol L) : cardinal.mk_list_eq_mk (preterm_symbol L)
  ... ≤ max (cardinal.sum (λ n : ulift.{u} (ℕ), #(L.functions n.down))) ω :
begin
  rw cardinal.mk_congr (preterm_symbol_equiv_fin_sum_formula_sum_nat L),
  simp only [...],
  apply le_trans (cardinal.add_le_max _ _) (max_le (max_le _ _) (le_max_right _ _)),
  { apply le_max_of_le_right,
    apply le_trans (cardinal.sum_le_sup.{u} (λ (i : ulift.{u} ℕ), (i.down : cardinal.{u}))),
    apply le_trans (cardinal.mul_le_max _ _) (max_le (max_le _ _) (le_of_eq rfl)),
    { simp },
    { rw cardinal.sup_le, intro i, apply le_of_lt, rw cardinal.lt_omega, simp, }
  },
  { apply le_trans (cardinal.add_le_max _ _) (max_le (max_le _ _) (le_max_right _ _)),
    { simp },
    { exact le_max_right _ _ } }
end \end{lstlisting}

\subsubsection{Formulas}

We make a similar construction for formulas,
where we bound the number of formulas by the number of terms.
We then utilize previous work bounding the number of terms by the
number of function symbols to improve the bound:
\begin{lstlisting}
lemma bounded_formula_le_bounded_term [is_algebraic L] {n} :
  #(bounded_formula L n) ≤ max (cardinal.sum (λ n : ulift.{u} ℕ, #(bounded_term L n.down))) ω := sorry

lemma bounded_formula_le_functions [is_algebraic L] {n} :
  #(bounded_formula L n) ≤ max (cardinal.sum (λ n : ulift.{u} ℕ, #(L.functions n.down))) ω :=
begin
  apply le_trans (bounded_formula_le_bounded_term L),
  apply max_le _ (le_max_right _ _),
  apply le_trans (cardinal.sum_le_sup _),
  simp only [cardinal.mk_denumerable],
  apply le_trans (cardinal.mul_le_max _ _),
  apply max_le _ (le_max_right _ _),
  apply max_le (le_max_right _ _),
  rw cardinal.sup_le,
  intro i,
  apply bounded_preterm_le_functions,
end \end{lstlisting}

The \textbf{formula symbols} we need are

\begin{lstlisting}
inductive formula_symbol (L : Language.{u}) : Type u
| bot : formula_symbol
| eq : formula_symbol
| imp : formula_symbol
| all : formula_symbol
| term : Π (l : ℕ), bounded_term L l → formula_symbol
| nat : ℕ → formula_symbol \end{lstlisting}

The structure of induction on formulas is more interesting than
that of terms, since the constructor \texttt{bounded\_preformula.bd\_all} takes preformulas with $n + 1$ free variables and converts them to
preformulas with $n$ free variables.
Thus we must keep track of the data of the number of free variables
when we write a formula as a list of symbols.
We do so when we \textbf{inject} formulas into lists of formula symbols.

\begin{lstlisting}
def formula_symbol_of_formula [is_algebraic L] {n} :
  bounded_formula L n → list (formula_symbol L) :=
bounded_formula.rec2
  (λ l, [formula_symbol.nat l, formula_symbol.bot]) -- ⊥
  (λ l t s, [ formula_symbol.nat l, formula_symbol.eq ,
    formula_symbol.term l t , formula_symbol.term l s ]) -- t ≃ s
  (λ _ _ r, false.elim $ Language.is_algebraic.empty_relations _ r) -- bd_rel
  (λ l ϕ ψ lϕ lψ, (formula_symbol.nat l) :: (formula_symbol.nat (list.length lϕ))
    :: (formula_symbol.nat (list.length lψ)) :: formula_symbol.imp :: lϕ.append lψ ) -- ϕ ⟹ ψ
  (λ l ϕ lϕ, (formula_symbol.nat l) :: formula_symbol.all :: lϕ) -- ∀ ϕ \end{lstlisting}

Here we have taken advantage of an induction lemma made for \texttt{bounded\_{formula}}
rather than \texttt{bounded\_{preformula}}.
Note that the assumption \texttt{is\_{algebraic}} here means that we need not
worry about relation symbols.
A generalization of this work would have to include the relation symbols
in the final upper bound.

To show that this assignment is \textbf{injective},
we need to be careful.
For the induction to work on the \texttt{bd\_all} case,
we need the inducion hypothesis to include the statement about formulas
with $n+1$ many free variables.
(This is possible since we are not inducting on the naturals, but on formulas.)
We quickly find that we are in the territory of \texttt{heq},
since we need to ask for two terms of definitionally different types
\texttt{bounded\_formula L n} and \texttt{bounded\_formula L m} to be equal.
Thus we state it as follows:

\begin{lstlisting}
lemma formula_symbol_of_preformula_injective' [is_algebraic L] {n} : ∀ (x : bounded_formula L n)
  {m} (y : bounded_formula L m),
  formula_symbol_of_formula x = formula_symbol_of_formula y → x == y := sorry

lemma formula_symbol_of_preformula_injective [is_algebraic L] {n}:
  function.injective (@formula_symbol_of_formula L _ n) :=
begin
  intros x y hxy,
  have h := formula_symbol_of_preformula_injective' x y hxy,
  subst h,
end \end{lstlisting}

There are $6 * 6 = 36$ cases to check for the first lemma,
of which $30$ are quite easily resolved by applications of
\texttt{no\_confusion}.
The rest of the $6$ are resolved by careful handling of the induction
hypothesis and \texttt{heq}.

We find \textbf{an equivalent type}, whose cardinality is easy to compute:

\begin{lstlisting}
def formula_symbol_equiv_bounded_term_sum_nat :
  (formula_symbol L) ≃ ((Σ l : ulift.{u} ℕ, bounded_term L l.down) ⊕ ulift.{u} ℕ) := sorry \end{lstlisting}

Finally we conclude our computation.
By our injection into formula symbols,

\begin{lstlisting}
lemma bounded_formula_le_bounded_term [is_algebraic L] {n} :
  #(bounded_formula L n) ≤ max (cardinal.sum (λ n : ulift.{u} ℕ, #(bounded_term L n.down))) ω :=
calc #(bounded_formula L n) ≤ # (list (formula_symbol L)) :
    cardinal.mk_le_of_injective (formula_symbol_of_preformula_injective) \end{lstlisting}

Then since the type of formula symbols is infinite,
the size of lists is equal to its original size,
which is equal to the size of the equivalent type above.

\begin{lstlisting}

  ... = # (formula_symbol L) : cardinal.mk_list_eq_mk _
  ... = _ : cardinal.mk_congr formula_symbol_equiv_bounded_term_sum_nat \end{lstlisting}

The rest is simple cardinal arithmetic.

\begin{lstlisting}
  ... ≤ max (cardinal.sum (λ n : ulift.{u} ℕ, #(bounded_term L n.down))) ω : by {
  simp only [le_refl, and_true, cardinal.mk_denumerable, cardinal.mk_sum, cardinal.lift_omega,
    cardinal.mk_sigma, cardinal.lift_id],
  apply le_trans (cardinal.add_le_max _ _) (max_le (max_le _ _) (le_max_right _ _)),
  { exact le_max_left _ _ },
  { exact le_max_right _ _ } } \end{lstlisting}

\subsubsection{Henkinization}

\link{henkinization_cardinality}

We are showing

\begin{lstlisting}
lemma henkin_language_le_cardinal [is_algebraic L] {T : Theory L}
  {hconsis : is_consistent T} (hωκ : ω ≤ κ)
  (hLκ : ∀ n, # (L.functions n) ≤ κ) (n : ℕ) :
  #((@henkin_language _ _ hconsis).functions n) ≤ κ := sorry \end{lstlisting}

In \texttt{flypitch} they design a general process of taking the colimit
of a collection (directed diagram) of languages,
which specialises to making \texttt{henkin\_language}.
To bound the cardinality of the colimit of languages we just need that
\begin{itemize}
  \item The function symbols are some quotient of a coproduct of languages.
  \item The coproduct of languages is formalized as a sigma type,
        whose cardinality can be computed as a sum of cardinalities.
\end{itemize}

We make a general lemma,
which says if cardinal $\ka$ bounds the function symbols of each language
in the directed diagram then $\ka$ also bounds
the function symbols in the colimit of the directed diagram.

\begin{lstlisting}
lemma colimit_language_le_cardinal {F : colimit.directed_diagram_language ℕ'}
  (n : ℕ) (h : ∀ i : ℕ, # ((F.obj i).functions n) ≤ κ) :
  # ((colimit.colimit_language F).functions n) ≤ κ :=
begin
  apply le_trans cardinal.mk_quotient_le, \end{lstlisting}

The above says that since the function symbols are a quotient,
and the cardinality of a quotient type is bounded by the original type
it suffices that the original type (the coproduct of function symbols)
is bounded by $\ka$.

\begin{lstlisting}
  dsimp only [colimit.coproduct_of_directed_diagram],
  rw cardinal.mk_sigma, \end{lstlisting}

Since the coproduct is defined as a sigma type,
we simply take the cardinality of the sigma type,
which is a sum.
The rest is cardinal arithmetic.

\begin{lstlisting}
  rw cardinal.sum_nat,
  apply le_trans (cardinal.sum_le_sup _),
  simp only [cardinal.mk_denumerable],
  apply le_trans (cardinal.mul_le_max _ _) (max_le (max_le hωκ _) hωκ),
  rw cardinal.sup_le,
  intro i,
  cases i,
  apply h,
end
\end{lstlisting}

To apply this lemma to our situation,
we will need to show that at each inductive Henkinization step,
the language has function symbols bounded by $\ka$.
We prove this as well:

\begin{lstlisting}
lemma henkin_language_chain_obj_card [is_algebraic L] {T : Theory L}
  (hconsis : is_consistent T)
  (hLκ : ∀ n, # (L.functions n) ≤ κ) (i : ℕ) :
  ∀ (n : ℕ), # (((@henkin_language_chain L).obj i).functions n) ≤ κ := \end{lstlisting}

If we induct on $i$,
we can use the way in which each step in the Henkinization was built.
When $i = 0$ the language is just $L$ itself,
which has function symbols bounded by assumption.

\begin{lstlisting}
  simp only [henkin_language_chain, henkin_language_chain_objects],
  induction i with i hi,
  { apply hLκ },
\end{lstlisting}

For the inductive step, we should also case on $n$ since
we only add new constant symbols at each step.

\begin{lstlisting}
  { intro n,
    cases n with n,
    { rw cardinal.mk_congr (@henkin_language_functions_zero (@henkin_language_chain_objects L i)),
      simp only [cardinal.mk_sum, cardinal.lift_id],
      apply le_trans (cardinal.add_le_max _ _),
      refine max_le (max_le (hi _) _) hωκ,
      apply bounded_formula_card_le hωκ hi, },
    { rw cardinal.mk_congr (@henkin_language_functions_succ (@henkin_language_chain_objects L i) n),
      apply hi } }
end \end{lstlisting}

To explain the above:
\begin{itemize}
  \item The constant symbols of any successive language   (\texttt{henkin\_language\_chain\_object i.succ}) biject with
  constant symbols from the previous language together with
  formulas with a single variable from the previous language:
  \begin{lstlisting}
  henkin_language_functions (henkin_language_chain_objects i) 0 ≃
    (henkin_language_chain_objects i).functions 0 ⊕ bounded_formula (henkin_language_chain_objects i) 1 \end{lstlisting}
  Hence it suffices to bound the sum of the two cardinalities by $\ka$.
  By the induction hypothesis \texttt{hi} we have the bound for
  The constant symbols from the previous language.
  By our previous work \texttt{bounded\_formula\_card\_le} we also
  have a bound on the number of formulas in the previous language,
  given a bound on the number of function symbols by the induction hypothesis \texttt{hi} again.

  \item The function symbols with arity $n + 1$ of any successive language
        biject with the the function symbols with arity $n + 1$ from the
        previous language:
\begin{lstlisting}
  henkin_language_functions (henkin_language_chain_objects i) (n + 1) ≃
    (henkin_language_chain_objects i).functions (n + 1) \end{lstlisting}
        Hence by rewriting our goal to be the cardinality of this type
        we can conclude using the induction hypothesis \texttt{hi}. \end{itemize}

Using the above lemmas we prove the main result:

\begin{lstlisting}
lemma henkin_language_le_cardinal [is_algebraic L] {T : Theory L}
  {hconsis : is_consistent T}
  (hLκ : ∀ n, # (L.functions n) ≤ κ) (n : ℕ) :
  # ((@henkin_language _ _ hconsis).functions n) ≤ κ :=
begin
  apply colimit_language_le_cardinal hωκ,
  intro i,
  apply henkin_language_chain_obj_card hωκ hconsis hLκ,
end \end{lstlisting}
